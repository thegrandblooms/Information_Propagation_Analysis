{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c1718c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from top2vec import Top2Vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b4f1128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creation_time</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>followers</th>\n",
       "      <th>lists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-09-26 20:14:17+00:00</td>\n",
       "      <td>GregL_Intel</td>\n",
       "      <td>I am looking forward to Intel Fellow @brendang...</td>\n",
       "      <td>10</td>\n",
       "      <td>54</td>\n",
       "      <td>4123</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-09-26 20:11:39+00:00</td>\n",
       "      <td>GregL_Intel</td>\n",
       "      <td>Open software ecosystems are key to fostering ...</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>4123</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-09-21 18:48:59+00:00</td>\n",
       "      <td>GregL_Intel</td>\n",
       "      <td>“AI Everywhere” will require optimized hardwar...</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>4123</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-09-20 18:00:01+00:00</td>\n",
       "      <td>GregL_Intel</td>\n",
       "      <td>Our collaboration with @TU_Muenchen and the It...</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>4123</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-09-19 22:52:59+00:00</td>\n",
       "      <td>GregL_Intel</td>\n",
       "      <td>I am looking forward to having @AndrewYNg, fou...</td>\n",
       "      <td>19</td>\n",
       "      <td>85</td>\n",
       "      <td>4123</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63028</th>\n",
       "      <td>2020-04-15 16:15:57+00:00</td>\n",
       "      <td>BarryJOGorman</td>\n",
       "      <td>@S_dF speaking of 'daily digital habits' - int...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>909</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63029</th>\n",
       "      <td>2020-04-15 13:54:53+00:00</td>\n",
       "      <td>BarryJOGorman</td>\n",
       "      <td>@nyike - if 'pushing envelope' - will always m...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>909</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63030</th>\n",
       "      <td>2021-02-03 18:17:58+00:00</td>\n",
       "      <td>RahulRJB</td>\n",
       "      <td>Even the mighty fall\\n#FarmersProstest</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63031</th>\n",
       "      <td>2022-10-06 06:42:42+00:00</td>\n",
       "      <td>jonsadventures</td>\n",
       "      <td>I've been writing notes for my second year non...</td>\n",
       "      <td>10</td>\n",
       "      <td>62</td>\n",
       "      <td>99</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63032</th>\n",
       "      <td>2022-08-05 02:12:16+00:00</td>\n",
       "      <td>ericdongyx</td>\n",
       "      <td>GLM-130B: an open LLM with 130 billion paramet...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>92</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63033 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   creation_time            user  \\\n",
       "0      2022-09-26 20:14:17+00:00     GregL_Intel   \n",
       "1      2022-09-26 20:11:39+00:00     GregL_Intel   \n",
       "2      2022-09-21 18:48:59+00:00     GregL_Intel   \n",
       "3      2022-09-20 18:00:01+00:00     GregL_Intel   \n",
       "4      2022-09-19 22:52:59+00:00     GregL_Intel   \n",
       "...                          ...             ...   \n",
       "63028  2020-04-15 16:15:57+00:00   BarryJOGorman   \n",
       "63029  2020-04-15 13:54:53+00:00   BarryJOGorman   \n",
       "63030  2021-02-03 18:17:58+00:00        RahulRJB   \n",
       "63031  2022-10-06 06:42:42+00:00  jonsadventures   \n",
       "63032  2022-08-05 02:12:16+00:00      ericdongyx   \n",
       "\n",
       "                                                   tweet  retweets  favorites  \\\n",
       "0      I am looking forward to Intel Fellow @brendang...        10         54   \n",
       "1      Open software ecosystems are key to fostering ...         4         26   \n",
       "2      “AI Everywhere” will require optimized hardwar...        11         25   \n",
       "3      Our collaboration with @TU_Muenchen and the It...         2         12   \n",
       "4      I am looking forward to having @AndrewYNg, fou...        19         85   \n",
       "...                                                  ...       ...        ...   \n",
       "63028  @S_dF speaking of 'daily digital habits' - int...         2          1   \n",
       "63029  @nyike - if 'pushing envelope' - will always m...         1          0   \n",
       "63030             Even the mighty fall\\n#FarmersProstest         1          2   \n",
       "63031  I've been writing notes for my second year non...        10         62   \n",
       "63032  GLM-130B: an open LLM with 130 billion paramet...         1          3   \n",
       "\n",
       "       followers  lists  \n",
       "0           4123     41  \n",
       "1           4123     41  \n",
       "2           4123     41  \n",
       "3           4123     41  \n",
       "4           4123     41  \n",
       "...          ...    ...  \n",
       "63028        909    103  \n",
       "63029        909    103  \n",
       "63030         47      0  \n",
       "63031         99      4  \n",
       "63032         92      5  \n",
       "\n",
       "[63033 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading Data\n",
    "df = pd.read_csv('data/combined_data.csv', index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90ed4d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Occurrance Count: 63\n"
     ]
    }
   ],
   "source": [
    "# Separating tweet text as text documents\n",
    "docs = df.tweet.tolist()\n",
    "\n",
    "# Some cleanup of words that are not removed by Top2Vec's stopword cleaning:\n",
    "docs = [d.replace(\"https\", \"\") for d in docs]\n",
    "docs = [d.replace(\".co\", \"\") for d in docs]\n",
    "\n",
    "# Setting threshold for word frequency - this will determine how nuanced our topics are\n",
    "min_ct_for_topic = int(len(docs) / 1000) # Change the number in this equation to tune - higher numbers here increases topic ct\n",
    "print(f\"Min Occurrance Count: {min_ct_for_topic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bbc2534",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-11 12:54:38,541 - top2vec - INFO - Pre-processing documents for training\n",
      "2022-10-11 12:54:42,699 - top2vec - INFO - Creating joint document/word embedding\n",
      "2022-10-11 13:35:02,288 - top2vec - INFO - Creating lower dimension embedding of documents\n",
      "2022-10-11 13:35:43,536 - top2vec - INFO - Finding dense areas of documents\n",
      "2022-10-11 13:35:49,597 - top2vec - INFO - Finding topics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell took a total of 0:41:11.664962\n"
     ]
    }
   ],
   "source": [
    "# Building our Top2Vec model - this cell takes a long time to run!\n",
    "start = datetime.datetime.now()\n",
    "tv_model = Top2Vec(docs, \n",
    "#                    embedding_model='universal-sentence-encoder', \n",
    "                   min_count=min_ct_for_topic, \n",
    "                   workers=8, \n",
    "                   ngram_vocab=False, \n",
    "                   speed=\"deep-learn\")\n",
    "end = datetime.datetime.now(); elapsed = end-start\n",
    "print('Cell took a total of {}'.format(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95a03b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Topics:  433\n",
      "\n",
      "First 20 Topic Sizes: [718 543 479 472 469 460 435 433 417 414 406 400 386 384 379 353 347 347\n",
      " 342 334]\n"
     ]
    }
   ],
   "source": [
    "topic_sizes, topic_nums = tv_model.get_topic_sizes()\n",
    "topic_words, word_scores, topic_nums = tv_model.get_topics()\n",
    "\n",
    "print(\"Number of Topics: \",len(topic_nums))\n",
    "print()\n",
    "print(\"First 20 Topic Sizes:\", topic_sizes[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a8e8e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for examining our topics and tweet/topic relationships:\n",
    "def examine_topic(topic, model):\n",
    "    print('Main Keywords:')\n",
    "    print(topic_words[topic])\n",
    "    print('----------')\n",
    "    print('Keyword Importance:')\n",
    "    print(word_scores[topic]) # Look at word scores by topic\n",
    "    print('----------')\n",
    "    print('Sample Tweets:')\n",
    "    print('----------')\n",
    "    documents, document_scores, document_ids = model.search_documents_by_topic(topic_num=topic, num_docs=5)\n",
    "    for doc, score, doc_id in zip(documents, document_scores, document_ids):\n",
    "        print(f\"### Document: {doc_id}, Score: {score} ###\")\n",
    "        print(doc)\n",
    "        print('----------')\n",
    "\n",
    "# Individual Tweet Lookup\n",
    "def tweet_topic_lookup(tweet_int, model, df=df):\n",
    "    display(df.iloc[[tweet_int]].style.set_properties(**{'text-align': 'left'})) # Testing document correlation with DF by looking up tweets\n",
    "    display(model.get_documents_topics([tweet_int])[1]) # Look at top2vec confidence of single tweet\n",
    "    display(model.get_documents_topics([tweet_int])[2]) # Look at top2vec topic keywords compared to a single tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0c1d8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Keywords:\n",
      "['knows' 'gretl' 'econometrics' 'everybody' 'statistics' 'everything'\n",
      " 'nobody' 'else' 'datascience' 'gap' 'elon' 'doc' 'crazy' 'absolutely'\n",
      " 'god' 'talking' 'pdf' 'contributed' 'terrible' 'guy' 'programming'\n",
      " 'realize' 'fossil' 'wants' 'either' 'machines' 'somehow' 'statistical'\n",
      " 'none' 'gop' 'neuralnetworks' 'stuff' 'someone' 'function' 'package'\n",
      " 'oil' 'math' 'difference' 'selling' 'keeps' 'elonmusk' 'medicare'\n",
      " 'mathematics' 'republicans' 'jack' 'file' 'green' 'materials' 'anyone'\n",
      " 'he']\n",
      "----------\n",
      "Keyword Importance:\n",
      "[0.23365511 0.22360906 0.219239   0.12581164 0.11512724 0.11330457\n",
      " 0.10870527 0.10527524 0.10105331 0.0988408  0.08908126 0.08776836\n",
      " 0.08202932 0.0757618  0.07196143 0.06944071 0.06817529 0.06389932\n",
      " 0.06136418 0.06037543 0.05991491 0.05960588 0.05906182 0.05860115\n",
      " 0.05764069 0.05731321 0.05648596 0.05558082 0.05443136 0.05431063\n",
      " 0.05377773 0.05132705 0.05113176 0.05033844 0.05006592 0.04919706\n",
      " 0.04902262 0.04827056 0.04681633 0.04583693 0.04425872 0.04272848\n",
      " 0.04229828 0.0413739  0.04129212 0.04078665 0.04022858 0.03998564\n",
      " 0.0378615  0.03769651]\n",
      "----------\n",
      "Sample Tweets:\n",
      "----------\n",
      "### Document: 40246, Score: 0.8529356122016907 ###\n",
      "Fab knows!!! ://t/1pj03SccTW\n",
      "----------\n",
      "### Document: 46861, Score: 0.8292979001998901 ###\n",
      "@nft_uardians Bravery knows no borders. We are all UArdians.\n",
      "----------\n",
      "### Document: 54961, Score: 0.8267514109611511 ###\n",
      "“there is a crack in everything” ://t/4JWTFHVmW3\n",
      "----------\n",
      "### Document: 54177, Score: 0.8244035243988037 ###\n",
      "@insiliconot @inversebrah everything is borderline ponzi\n",
      "----------\n",
      "### Document: 62326, Score: 0.8204713463783264 ###\n",
      "Everything is temporary.\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "examine_topic(140, tv_model) # Examine specific topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8f28305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_da004_row0_col0, #T_da004_row0_col1, #T_da004_row0_col2, #T_da004_row0_col3, #T_da004_row0_col4, #T_da004_row0_col5, #T_da004_row0_col6 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_da004_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >creation_time</th>\n",
       "      <th class=\"col_heading level0 col1\" >user</th>\n",
       "      <th class=\"col_heading level0 col2\" >tweet</th>\n",
       "      <th class=\"col_heading level0 col3\" >retweets</th>\n",
       "      <th class=\"col_heading level0 col4\" >favorites</th>\n",
       "      <th class=\"col_heading level0 col5\" >followers</th>\n",
       "      <th class=\"col_heading level0 col6\" >lists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_da004_level0_row0\" class=\"row_heading level0 row0\" >4612</th>\n",
       "      <td id=\"T_da004_row0_col0\" class=\"data row0 col0\" >2022-08-02 15:39:31+00:00</td>\n",
       "      <td id=\"T_da004_row0_col1\" class=\"data row0 col1\" >benthompson</td>\n",
       "      <td id=\"T_da004_row0_col2\" class=\"data row0 col2\" >Thank you for the warm welcome back Taiwan! https://t.co/bAJP0r4f3k</td>\n",
       "      <td id=\"T_da004_row0_col3\" class=\"data row0 col3\" >5</td>\n",
       "      <td id=\"T_da004_row0_col4\" class=\"data row0 col4\" >135</td>\n",
       "      <td id=\"T_da004_row0_col5\" class=\"data row0 col5\" >224268</td>\n",
       "      <td id=\"T_da004_row0_col6\" class=\"data row0 col6\" >5978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17722a8ef70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.50866127], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([['ocean', 'fire', 'weekend', 'classes', 'mentor', 'midjourney',\n",
       "        'lecture', 'chairs', 'ipcc', 'friday', 'warm', 'pr', 'tips',\n",
       "        'conflict', 'appreciate', 'managing', 'digitalart', 'lucky',\n",
       "        'distance', 'lectures', 'forever', 'card', 'christmas',\n",
       "        'graduate', 'sea', 'ambassador', 'scholarship', 'dreams',\n",
       "        'harvard', 'god', 'astra', 'trading', 'gift', 'beta', 'county',\n",
       "        'walk', 'send', 'father', 'okay', 'program', 'ex', 'forms',\n",
       "        'max', 'shares', 'generativeart', 'guys', 'yourself', 'title',\n",
       "        'clarkwa', 'mental']], dtype='<U15')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweet_topic_lookup(4612, tv_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ccfeacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loop - look up each document and append the topic ID to the original dataframe\n",
    "topic_ids = []\n",
    "for doc in tv_model.document_ids: # model.document_ids # List of all document IDs\n",
    "    # tv_model.get_documents_topics([doc])[1][0] # Grabbing Confidence\n",
    "    topic_ids.append(tv_model.get_documents_topics([doc])[0][0]) # Grabbing Topic ID\n",
    "df['topic'] = topic_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976cd41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Saving Topics\n",
    "# df['topic'].to_csv('data/topics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d71892c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
