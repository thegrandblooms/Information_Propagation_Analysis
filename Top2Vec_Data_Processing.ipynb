{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31163d59",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86e193ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from top2vec import Top2Vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc399328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creation_time</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>followers</th>\n",
       "      <th>lists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-09-26 20:14:17+00:00</td>\n",
       "      <td>GregL_Intel</td>\n",
       "      <td>I am looking forward to Intel Fellow @brendang...</td>\n",
       "      <td>10</td>\n",
       "      <td>54</td>\n",
       "      <td>4123</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-09-26 20:11:39+00:00</td>\n",
       "      <td>GregL_Intel</td>\n",
       "      <td>Open software ecosystems are key to fostering ...</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>4123</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-09-21 18:48:59+00:00</td>\n",
       "      <td>GregL_Intel</td>\n",
       "      <td>“AI Everywhere” will require optimized hardwar...</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>4123</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-09-20 18:00:01+00:00</td>\n",
       "      <td>GregL_Intel</td>\n",
       "      <td>Our collaboration with @TU_Muenchen and the It...</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>4123</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-09-19 22:52:59+00:00</td>\n",
       "      <td>GregL_Intel</td>\n",
       "      <td>I am looking forward to having @AndrewYNg, fou...</td>\n",
       "      <td>19</td>\n",
       "      <td>85</td>\n",
       "      <td>4123</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63028</th>\n",
       "      <td>2020-04-15 16:15:57+00:00</td>\n",
       "      <td>BarryJOGorman</td>\n",
       "      <td>@S_dF speaking of 'daily digital habits' - int...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>909</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63029</th>\n",
       "      <td>2020-04-15 13:54:53+00:00</td>\n",
       "      <td>BarryJOGorman</td>\n",
       "      <td>@nyike - if 'pushing envelope' - will always m...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>909</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63030</th>\n",
       "      <td>2021-02-03 18:17:58+00:00</td>\n",
       "      <td>RahulRJB</td>\n",
       "      <td>Even the mighty fall\\n#FarmersProstest</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63031</th>\n",
       "      <td>2022-10-06 06:42:42+00:00</td>\n",
       "      <td>jonsadventures</td>\n",
       "      <td>I've been writing notes for my second year non...</td>\n",
       "      <td>10</td>\n",
       "      <td>62</td>\n",
       "      <td>99</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63032</th>\n",
       "      <td>2022-08-05 02:12:16+00:00</td>\n",
       "      <td>ericdongyx</td>\n",
       "      <td>GLM-130B: an open LLM with 130 billion paramet...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>92</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63033 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   creation_time            user  \\\n",
       "0      2022-09-26 20:14:17+00:00     GregL_Intel   \n",
       "1      2022-09-26 20:11:39+00:00     GregL_Intel   \n",
       "2      2022-09-21 18:48:59+00:00     GregL_Intel   \n",
       "3      2022-09-20 18:00:01+00:00     GregL_Intel   \n",
       "4      2022-09-19 22:52:59+00:00     GregL_Intel   \n",
       "...                          ...             ...   \n",
       "63028  2020-04-15 16:15:57+00:00   BarryJOGorman   \n",
       "63029  2020-04-15 13:54:53+00:00   BarryJOGorman   \n",
       "63030  2021-02-03 18:17:58+00:00        RahulRJB   \n",
       "63031  2022-10-06 06:42:42+00:00  jonsadventures   \n",
       "63032  2022-08-05 02:12:16+00:00      ericdongyx   \n",
       "\n",
       "                                                   tweet  retweets  favorites  \\\n",
       "0      I am looking forward to Intel Fellow @brendang...        10         54   \n",
       "1      Open software ecosystems are key to fostering ...         4         26   \n",
       "2      “AI Everywhere” will require optimized hardwar...        11         25   \n",
       "3      Our collaboration with @TU_Muenchen and the It...         2         12   \n",
       "4      I am looking forward to having @AndrewYNg, fou...        19         85   \n",
       "...                                                  ...       ...        ...   \n",
       "63028  @S_dF speaking of 'daily digital habits' - int...         2          1   \n",
       "63029  @nyike - if 'pushing envelope' - will always m...         1          0   \n",
       "63030             Even the mighty fall\\n#FarmersProstest         1          2   \n",
       "63031  I've been writing notes for my second year non...        10         62   \n",
       "63032  GLM-130B: an open LLM with 130 billion paramet...         1          3   \n",
       "\n",
       "       followers  lists  \n",
       "0           4123     41  \n",
       "1           4123     41  \n",
       "2           4123     41  \n",
       "3           4123     41  \n",
       "4           4123     41  \n",
       "...          ...    ...  \n",
       "63028        909    103  \n",
       "63029        909    103  \n",
       "63030         47      0  \n",
       "63031         99      4  \n",
       "63032         92      5  \n",
       "\n",
       "[63033 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading Data\n",
    "df = pd.read_csv('data/combined_data.csv', index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b239fe8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Occurrance Count: 63\n"
     ]
    }
   ],
   "source": [
    "# Separating tweet text as text documents\n",
    "docs = df.tweet.tolist()\n",
    "\n",
    "# Some cleanup of words that are not removed by Top2Vec's stopword cleaning:\n",
    "docs = [d.replace(\"https\", \"\") for d in docs]\n",
    "docs = [d.replace(\".co\", \"\") for d in docs]\n",
    "\n",
    "# Setting threshold for word frequency - this will determine how nuanced our topics are\n",
    "min_ct_for_topic = int(len(docs) / 1000) # Change the number in this equation to tune - higher numbers here increases topic ct\n",
    "print(f\"Min Occurrance Count: {min_ct_for_topic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c09db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building our Top2Vec model - this cell takes a long time to run!\n",
    "start = datetime.datetime.now()\n",
    "tv_model = Top2Vec(docs, \n",
    "#                    embedding_model='universal-sentence-encoder', \n",
    "                   min_count=min_ct_for_topic, \n",
    "                   workers=8, \n",
    "                   ngram_vocab=False, \n",
    "                   speed=\"deep-learn\")\n",
    "end = datetime.datetime.now(); elapsed = end-start\n",
    "print('Cell took a total of {}'.format(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f10142e",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_sizes, topic_nums = tv_model.get_topic_sizes()\n",
    "topic_words, word_scores, topic_nums = tv_model.get_topics()\n",
    "\n",
    "print(\"Number of Topics: \",len(topic_nums))\n",
    "print()\n",
    "print(\"First 20 Topic Sizes:\", topic_sizes[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68cf4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for examining our topics and tweet/topic relationships:\n",
    "def examine_topic(topic, model):\n",
    "    print('Main Keywords:')\n",
    "    print(topic_words[topic])\n",
    "    print('----------')\n",
    "    print('Keyword Importance:')\n",
    "    print(word_scores[topic]) # Look at word scores by topic\n",
    "    print('----------')\n",
    "    print('Sample Tweets:')\n",
    "    print('----------')\n",
    "    documents, document_scores, document_ids = model.search_documents_by_topic(topic_num=topic, num_docs=5)\n",
    "    for doc, score, doc_id in zip(documents, document_scores, document_ids):\n",
    "        print(f\"### Document: {doc_id}, Score: {score} ###\")\n",
    "        print(doc)\n",
    "        print('----------')\n",
    "\n",
    "# Individual Tweet Lookup\n",
    "def tweet_topic_lookup(tweet_int, model, df=df):\n",
    "    display(df.iloc[[tweet_int]].style.set_properties(**{'text-align': 'left'})) # Testing document correlation with DF by looking up tweets\n",
    "    display(model.get_documents_topics([tweet_int])[1]) # Look at top2vec confidence of single tweet\n",
    "    display(model.get_documents_topics([tweet_int])[2]) # Look at top2vec topic keywords compared to a single tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98816e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "examine_topic(140, tv_model) # Examine specific topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bc711a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_topic_lookup(61127, tv_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d397502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loop - look up each document and append the topic ID to the original dataframe\n",
    "topic_ids = []\n",
    "for doc in tv_model.document_ids: # model.document_ids # List of all document IDs\n",
    "    # tv_model.get_documents_topics([doc])[1][0] # Grabbing Confidence\n",
    "    topic_ids.append(tv_model.get_documents_topics([doc])[0][0]) # Grabbing Topic ID\n",
    "df['topic'] = topic_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddace944",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['topic'].to_csv('data/topics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0848e5eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
